# üìö Assistant d'entra√Ænement au droit des brevets

Nous proposons ce rendu dans le cadre du data challenge de [l'association IA PAU](https://iapau.org/).
Ce projet propose un assistant p√©dagogique pour les √©tudiants en droit des brevets, capable de g√©n√©rer des questions d'examen r√©alistes et de fournir une √©valuation automatique des r√©ponses, avec des justifications juridiques extraites de textes officiels (EPC, PCT, Guidelines...).

---
## Auteurs

- GADZINA Guillaume
- BERGES Julien
- AUR√â Nolhan
  
‚ö†Ô∏è Sur CPU uniquement c'est tr√®s long !
### 1. Pr√©requis 
- Ollama install√© sur votre machine [https://ollama.com/download]
- Python3.11 minimum

### 2. Lancement

#### √âtape 1 : Cloner le d√©p√¥t 
  ```sh
    git clone https://github.com/nolhanaure/data_battle_paulympe.git
    cd data_battle_paulympe
  ```    

#### √âtape 2 : Pr√©paration de l'environnement 
Sous linux : 
  ```sh
    chmod 744 setup.sh
    ./setup.sh
  ```

Sous Windows : 
  ```sh
    .\setup.bat
  ```

#### √âtape 2 : Pr√©paration de l'environnement 
Front : 
  ```sh
    cd frontend
    npm install
    npm run dev
  ```

Dans un autre terminal, backend : 
  ```sh
    cd backend
    python3.11 -m uvicorn app:app --reload
  ```
#### √âtape 3 : Ouverture dans le navigateur
Utilisez l'URL suivant dans votre navigateur:  
     http://localhost:5173

Ensuite, vous pouvez choisir entre question √† th√®me, question al√©atoire ou alors mettre votre propre question. R√©pondez-y et l'IA l'analysera et fournira une analyse d√©taill√©e. Si jamais vous n'avez pas la r√©ponse, il suffit de cliquer sur "Je n'ai pas la r√©ponse" pour que l'IA g√©n√®re un mod√®le de r√©ponse.
## üóÇÔ∏è Arborescence du projet

Voici une description de l'arborescence du projet, en expliquant le r√¥le de chaque r√©pertoire et fichier important :

---

### üîß `backend/` : Partie backend avec FastAPI et embeddings IA
- `app.py` : API FastAPI principale (g√©n√©ration de questions, analyse de r√©ponses).
- `index_faiss/` : Index FAISS final, utilis√© pour la recherche de documents vectoris√©s.
- `data_preparation/` : Scripts de nettoyage, parsing et transformation des textes.
- `json/` : Fichiers QCM nettoy√©s au format JSON (question / r√©ponse).
- `Official_Legal_Publications_TXT/` : Textes l√©gaux officiels bruts ou nettoy√©s.
  - `EPC/` : Convention EPC, R√®glement d'application, Protocoles, etc. nettoy√©s.
- `data_base/` : Versions brutes ou anciennes des fichiers.
- - `logs/` : Logs req√™tes endpoint codecarbon
- `emissions.csv` : Mesure de la consommation √©nerg√©tique (outil CodeCarbon).

---

### üíª `frontend/` : Interface utilisateur React
- `public/` : Fichiers statiques accessibles (favicon, index.html...).
- `src/` : Composants React :
  - UI (pages, boutons, formulaire)
  - Appels √† l‚ÄôAPI FastAPI (fetch des questions, analyse des r√©ponses)
- `package.json` : D√©pendances Node.js et scripts de d√©veloppement.


---

## ‚öôÔ∏è Fonctionnalit√©s principales

- üîé **Recherche de contexte juridique** via FAISS et LangChain
- üß† **G√©n√©ration de questions d'examen** (MCQ ou ouvertes) √† partir du contexte juridique, √† choix multiples ou ouvert, sur un th√®me choisi ou non.
- ‚úÖ **Analyse automatique des r√©ponses** avec feedback, √©valuation, justification et base l√©gale
- üå± **D√©ploiement 100% local** via Ollama + mod√®le Mistral, sans d√©pendance cloud

---

## üß† Technologies utilis√©es

- **LangChain** ‚Äì Cha√Æne RAG (Retrieval-Augmented Generation)
- **FAISS** ‚Äì Index vectoriel performant pour la recherche s√©mantique
- **BAAI/bge-m3** ‚Äì  Mod√®le de type embedding g√©n√©raliste pour encoder efficacement questions et documents juridiques.
- **Ollama** ‚Äì Ex√©cution locale de LLM (Mistral 7B)
- **FastAPI** ‚Äì API backend
- **CodeCarbon** ‚Äì Estimation de l'empreinte carbone du traitement local
- **React** : Frontend interactif avec appels dynamiques √† l‚ÄôAPI.

---

## üåç Enjeux environnementaux

Le syst√®me a √©t√© pens√© pour **minimiser son impact √©cologique** :
- Aucun appel cloud/API externe
- Mod√®les LLM ex√©cut√©s localement
- Embedding fait une seule fois en batch, index persist√©
- √Ä chaque appel d'un endpoint du backend, nous utilisons la biblioth√®que CodeCarbon pour estimer en temps r√©el les √©missions de CO‚ÇÇ li√©es √† l'ex√©cution. Le tracker s‚Äôactive au d√©but de chaque traitement (ex. : g√©n√©ration de question ou analyse de r√©ponse) et s‚Äôarr√™te automatiquement apr√®s. Cela permet de mesurer de mani√®re pr√©cise la consommation √©nerg√©tique de chaque requ√™te. En plus de l'affichage dans la console, toutes les interactions sont enregistr√©es dans un fichier JSONL (interactions_log.jsonl) situ√© dans le dossier backend/logs
---

## üß† Design de la d√©cision

Chaque d√©cision technique (nettoyage manuel, infrastructure, mod√®le, etc.) a √©t√© guid√©e par :
- **Pertinence p√©dagogique**
- **Sobri√©t√© √©nerg√©tique**
- **Clart√© de la cha√Æne de traitement**
- **Explicabilit√© des choix IA**

---
